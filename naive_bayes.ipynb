{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load Data from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "train = pd.read_csv(data_dir + '/train.csv')  \n",
    "test = pd.read_csv(data_dir + '/test.csv')\n",
    "test_labels = pd.read_csv(data_dir + '/test_labels.csv')\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
       "3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
       "4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  \n",
       "1             -1  \n",
       "2             -1  \n",
       "3             -1  \n",
       "4             -1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(153164, 2)\n",
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "print (train.shape)\n",
    "print (test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Clean the text following the Naive Bayes class\n",
    "    * Get rid of non alphabets\n",
    "    * Transform the data into full_train_x, full_train_y and test_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  #正则表达式\n",
    "\n",
    "def review_preprocessing(review):\n",
    "    # Clean some texts and only keep English.\n",
    "    review = re.sub(r\"what's\", \"what is \", review)\n",
    "    review = re.sub(r\"\\'s\", \" \", review)\n",
    "    review = re.sub(r\"\\'ve\", \" have \", review)\n",
    "    review = re.sub(r\"can't\", \"cannot \", review)\n",
    "    review = re.sub(r\"n't\", \" not \", review)\n",
    "    review = re.sub(r\"i'm\", \"i am \", review)\n",
    "    review = re.sub(r\"\\'re\", \" are \", review)\n",
    "    review = re.sub(r\"\\'d\", \" would \", review)\n",
    "    review = re.sub(r\"\\'ll\", \" will \", review)\n",
    "    review = re.sub(r\"\\'scuse\", \" excuse \", review)\n",
    "    review = re.sub('\\W', ' ', review)\n",
    "    review = re.sub('\\s+', ' ', review)\n",
    "    review = review.strip(' ')\n",
    "    \n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    #Change to lower format\n",
    "    words = review_text.lower()\n",
    "    \n",
    "    return(words)\n",
    "\n",
    "def prepare_training_data(train, y, x):\n",
    "    # 把训练集的文本和标注分开\n",
    "    # 1. 把标注提取出来\n",
    "    full_train_y = train[y]\n",
    "    \n",
    "    # 2. 把文本提取出来\n",
    "    full_train_x = []\n",
    "    for review in train[x]:\n",
    "        full_train_x.append(review_preprocessing(review))\n",
    "    \n",
    "    # 3. 转化成numpy数组        \n",
    "    full_train_x = np.array(full_train_x)\n",
    "    return full_train_x, full_train_y\n",
    "\n",
    "def prepare_test_data(test, x):\n",
    "    test_data = []\n",
    "    \n",
    "    for review in test['comment_text']:\n",
    "        test_data.append(review_preprocessing(review))\n",
    "        \n",
    "    test_data = np.array(test_data)\n",
    "    return test_data\n",
    "\n",
    "full_train_toxic_x, full_train_toxic_y = prepare_training_data(train, 'toxic', 'comment_text')\n",
    "full_train_stoxic_x, full_train_stoxic_y = prepare_training_data(train, 'severe_toxic', 'comment_text')\n",
    "full_train_obscene_x, full_train_obscene_y = prepare_training_data(train, 'obscene', 'comment_text')\n",
    "full_train_threat_x, full_train_threat_y = prepare_training_data(train, 'threat', 'comment_text')\n",
    "full_train_insult_x, full_train_insult_y = prepare_training_data(train, 'insult', 'comment_text')\n",
    "full_train_identityhate_x, full_train_identityhate_y = prepare_training_data(train, 'identity_hate', 'comment_text')\n",
    "\n",
    "test_data = prepare_test_data(test, 'comment_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571,)\n",
      "(159571,)\n",
      "(159571,)\n",
      "(159571,)\n",
      "(159571,)\n",
      "(159571,)\n",
      "(153164,)\n"
     ]
    }
   ],
   "source": [
    "print(full_train_toxic_x.shape)\n",
    "print(full_train_stoxic_x.shape)\n",
    "print(full_train_obscene_x.shape)\n",
    "print(full_train_threat_x.shape)\n",
    "print(full_train_insult_x.shape)\n",
    "print(full_train_identityhate_x.shape)\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def naive_bayes_test_train(x, y):\n",
    "    data_train, data_validation, labels_train, labels_validation = train_test_split(\n",
    "        x,\n",
    "        y, \n",
    "        test_size = 0.2, \n",
    "        random_state = 0) \n",
    "    \n",
    "    # 使用简单的计数\n",
    "    vectorizer = CountVectorizer()\n",
    "    data_train_count = vectorizer.fit_transform(data_train)\n",
    "    data_validation_count  = vectorizer.transform(data_validation)\n",
    "\n",
    "    print(\"data split ready\")\n",
    "    \n",
    "    # 使用tf-idf\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_data_train_count = tfidf_vectorizer.fit_transform(data_train)\n",
    "    tfidf_data_validation_count  = tfidf_vectorizer.transform(data_validation)\n",
    "    \n",
    "    # 使用tf-idf with n-gram and stop words\n",
    "    advance_tfidf_vectorizer = TfidfVectorizer(\n",
    "               ngram_range=(1, 3),  # 二元文法模型\n",
    "               stop_words = 'english') # 去掉英文停用词\n",
    "\n",
    "    advance_tfidf_data_train_count = advance_tfidf_vectorizer.fit_transform(data_train)\n",
    "    advance_tfidf_data_validation_count  = advance_tfidf_vectorizer.transform(data_validation)\n",
    "    \n",
    "    print(\"training data\")\n",
    "    \n",
    "    # 多项式朴素贝叶斯\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "\n",
    "    # 用Validation Set选择模型\n",
    "    clf.fit(data_train_count, labels_train)\n",
    "    pred = clf.predict(data_validation_count)\n",
    "    print (\"Counter Accuracy:\", accuracy_score(labels_validation, pred))\n",
    "\n",
    "    clf.fit(tfidf_data_train_count, labels_train)\n",
    "    tfidf_pred = clf.predict(tfidf_data_validation_count)\n",
    "    print (\"TFIDF Accuracy:\", accuracy_score(labels_validation, tfidf_pred))\n",
    "\n",
    "    clf.fit(advance_tfidf_data_train_count, labels_train)\n",
    "    advance_tfidf_pred = clf.predict(advance_tfidf_data_validation_count)\n",
    "    print (\"Advance TFIDF Accuracy:\", accuracy_score(labels_validation, advance_tfidf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split ready\n",
      "training data\n",
      "Counter Accuracy: 0.9472348425505248\n",
      "TFIDF Accuracy: 0.9187529374902084\n",
      "Advance TFIDF Accuracy: 0.9092276359078804\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_test_train(full_train_toxic_x,full_train_toxic_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split ready\n",
      "training data\n",
      "Counter Accuracy: 0.9871220429265236\n",
      "TFIDF Accuracy: 0.989691367695441\n",
      "Advance TFIDF Accuracy: 0.989691367695441\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_test_train(full_train_stoxic_x,full_train_stoxic_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split ready\n",
      "training data\n",
      "Counter Accuracy: 0.9669434435218549\n",
      "TFIDF Accuracy: 0.9520914930283566\n",
      "Advance TFIDF Accuracy: 0.9486448378505405\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_test_train(full_train_obscene_x,full_train_obscene_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split ready\n",
      "training data\n",
      "Counter Accuracy: 0.9965220115932947\n",
      "TFIDF Accuracy: 0.9971486761710794\n",
      "Advance TFIDF Accuracy: 0.9971486761710794\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_test_train(full_train_threat_x,full_train_threat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split ready\n",
      "training data\n",
      "Counter Accuracy: 0.9644054519818267\n",
      "TFIDF Accuracy: 0.9519034936550211\n",
      "Advance TFIDF Accuracy: 0.9503368322105593\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_test_train(full_train_insult_x,full_train_insult_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split ready\n",
      "training data\n",
      "Counter Accuracy: 0.9891587028043239\n",
      "TFIDF Accuracy: 0.9906626977910074\n",
      "Advance TFIDF Accuracy: 0.9906626977910074\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_test_train(full_train_identityhate_x,full_train_identityhate_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Choose the best accuracy model and export result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def naive_bayes_full_train(x, y, test_data, model):\n",
    "    if model == 'advance':\n",
    "        # 全量训练\n",
    "        advance_tfidf_vectorizer = TfidfVectorizer(\n",
    "               ngram_range=(1, 3),  # 二元文法模型\n",
    "               stop_words = 'english') # 去掉英文停用词\n",
    "        full_data_train_count = advance_tfidf_vectorizer.fit_transform(x)\n",
    "        data_test_count  = advance_tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "    elif model == 'counter':\n",
    "         # 全量训练\n",
    "        vectorizer = CountVectorizer()\n",
    "        full_data_train_count = vectorizer.fit_transform(x)\n",
    "        data_test_count  = vectorizer.transform(test_data)\n",
    "        \n",
    "    elif model == '':\n",
    "         # 全量训练\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        full_data_train_count = tfidf_vectorizer.fit_transform(x)\n",
    "        data_test_count  = tfidf_vectorizer.transform(test_data)\n",
    "        \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(full_data_train_count, y)\n",
    "    # 最终测试\n",
    "    pred = clf.predict(data_test_count)\n",
    "    print(len(pred))   \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164\n",
      "153164\n",
      "153164\n",
      "153164\n",
      "153164\n",
      "153164\n"
     ]
    }
   ],
   "source": [
    "pred_toxic = naive_bayes_full_train(full_train_toxic_x,full_train_toxic_y, test_data, 'counter')\n",
    "pred_stoxic = naive_bayes_full_train(full_train_stoxic_x,full_train_stoxic_y, test_data, 'advance')\n",
    "pred_obscene = naive_bayes_full_train(full_train_obscene_x,full_train_obscene_y, test_data, 'counter')\n",
    "pred_threat = naive_bayes_full_train(full_train_threat_x,full_train_threat_y, test_data, 'advance')\n",
    "pred_insult = naive_bayes_full_train(full_train_insult_x,full_train_insult_y, test_data, 'counter')\n",
    "pred_identityhate = naive_bayes_full_train(full_train_identityhate_x,full_train_identityhate_y, test_data, 'advance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把结果保存到csv文件中，并进行提交: https://www.kaggle.com/c/word2vec-nlp-tutorial/leaderboard\n",
    "df = pd.DataFrame({\"id\": test['id']\n",
    "                   ,\"toxic\": pred_toxic\n",
    "                   ,\"severe_toxic\" : pred_stoxic\n",
    "                   ,\"obscene\" : pred_obscene\n",
    "                   ,\"threat\" : pred_threat\n",
    "                   ,\"insult\" : pred_insult\n",
    "                   ,\"identityhate\" : pred_identityhate\n",
    "                  })\n",
    "\n",
    "df.to_csv('submission.csv',index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing d: 100%|██████████| 4/4 [00:01<00:00,  3.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "#for i in trange(100):\n",
    "#    pass\n",
    "\n",
    "pbar = tqdm([\"a\", \"b\", \"c\", \"d\"])\n",
    "for char in pbar:\n",
    "    sleep(0.25)\n",
    "    pbar.set_description(\"Processing %s\" % char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
